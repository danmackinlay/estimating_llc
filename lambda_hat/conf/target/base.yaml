# Two-stage: Stage A (build-target)
defaults:
  - model: small
  - data: small
  - teacher: _null
  - _self_

jax:
  enable_x64: true

target:
  seed: 42
  # Exclude volatile elements like code_sha. Ensure 'training' is included.
  id: ${fingerprint:${model},${data},${training},${teacher},${.seed}}

# Ensure artifacts root is stable across single runs and multiruns
store:
  root: ${hydra:runtime.cwd}/runs

runtime:
  code_sha: ${git_sha:}
  hostname: ${hostname:}

# Training block (used by your ERM)
training:
  optimizer: adam
  learning_rate: 0.001
  steps: 5000
  early_stop_tol: 1e-6
  batch_size: null  # Use full batch by default

# Teacher configuration is loaded via config group defaults (teacher: _null)